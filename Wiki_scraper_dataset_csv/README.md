# Wiki Scraper

wiki_webpage -> scraper -> dataset.csv

This is example of scraping some wiki webpage to get certain information

With this scraper we scrape all data on the wiki webpage based on birthdate information

We collect data of all persons based on birth month and save the needed data in
csv dataset 'person_data.csv'

##########################################################################

Dataset 'person_data.csv' looks like this:

Name/Surname,Birthdate,Birth Location
</br>name_surname,"Month Day, Year", "Birth_location"

The first line is header, the second line is general data format.

When the dataset is created by this wiki parser, it needs to be cleaned.

Data cleaning of this dataset is necessary.

When the dataset is cleaned, we can go into next processing of data the way we want